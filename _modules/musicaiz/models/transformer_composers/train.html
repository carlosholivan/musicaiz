<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>musicaiz.models.transformer_composers.train &mdash; Musicaiz 0.0.2 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/design-tabs.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #222222ff" >
            <a href="../../../../index.html">
            <img src="../../../../_static/logo_square_dark.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.0.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../install.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../introduction.html">Introduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Musicaiz Documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../loaders.html">Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../structure.html">Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../harmony.html">Harmony</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rhythm.html">Rhythm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../algorithms.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tokenizers.html">Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../evaluation.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../plotters.html">Plotters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebooks/2-write_midi.html">Writing a MIDI file from scratch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebooks/3-plot.html">Plotting</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../implementations.html">Implementation Details</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../glossary.html">Glossary</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #222222ff" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Musicaiz</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>musicaiz.models.transformer_composers.train</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for musicaiz.models.transformer_composers.train</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">apex</span> <span class="kn">import</span> <span class="n">amp</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">from</span> <span class="nn">prettytable</span> <span class="kn">import</span> <span class="n">PrettyTable</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># gpt_composer sub-package</span>
<span class="kn">from</span> <span class="nn">musicaiz.models.transformer_composers.configs</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">GPTConfigs</span><span class="p">,</span>
    <span class="n">TrainConfigs</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">musicaiz.models.transformer_composers.dataset</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">build_torch_loaders</span><span class="p">,</span>
    <span class="n">get_vocabulary</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">musicaiz.models.transformer_composers.transformers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">GPT2</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">initialize_model</span><span class="p">(</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">configs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">):</span>
    <span class="n">confs</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="s2">&quot;model_configs&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;gpt&quot;</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">GPT2</span><span class="p">(</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="n">confs</span><span class="p">[</span><span class="s2">&quot;VOCAB_SIZE&quot;</span><span class="p">],</span>
            <span class="n">embedding_dim</span><span class="o">=</span><span class="n">confs</span><span class="p">[</span><span class="s2">&quot;EMBED_DIM&quot;</span><span class="p">],</span>
            <span class="n">n_decoders</span><span class="o">=</span><span class="n">confs</span><span class="p">[</span><span class="s2">&quot;N_DECODERS&quot;</span><span class="p">],</span>
            <span class="n">sequence_len</span><span class="o">=</span><span class="n">confs</span><span class="p">[</span><span class="s2">&quot;SEQ_LEN&quot;</span><span class="p">],</span>
            <span class="n">n_heads</span><span class="o">=</span><span class="n">confs</span><span class="p">[</span><span class="s2">&quot;N_HEADS&quot;</span><span class="p">],</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<div class="viewcode-block" id="train"><a class="viewcode-back" href="../../../../generated/generated/musicaiz.models.transformer_composers.train.html#musicaiz.models.transformer_composers.train">[docs]</a><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="n">dataset_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">],</span>
    <span class="n">sequence_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">GPTConfigs</span><span class="o">.</span><span class="n">SEQ_LEN</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">train_split</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">TRAIN_SPLIT</span><span class="p">,</span>
    <span class="n">is_splitted</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">LR</span><span class="p">,</span>
    <span class="n">adam_epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">ADAM_EPSILON</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">GRAD_ACUM_STEPS</span><span class="p">,</span>
    <span class="n">fp16</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">FP16</span><span class="p">,</span>
    <span class="n">fp16_opt_level</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">FP16_OPT_LEVEL</span><span class="p">,</span>
    <span class="n">log_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">LOG_STEPS</span><span class="p">,</span>
    <span class="n">ckpt_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">CKPT_STEPS</span><span class="p">,</span>
    <span class="n">checkpoint_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span>
    <span class="n">log_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">LOG_DIR</span><span class="p">,</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="n">MODEL_NAME</span>
<span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dataset_path: Union[str, Path]</span>

<span class="sd">    sequence_length: int</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2Configs.SEQ_LEN`</span>

<span class="sd">    batch_size: int</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2Configs.BATCH_SIZE`</span>

<span class="sd">    embedding_dim: int</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2Configs.EMBED_DIM`</span>

<span class="sd">    n_decoders: int</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2Configs.N_DECODERS`</span>

<span class="sd">    n_heads: int</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2Configs.N_HEADS`</span>

<span class="sd">    dropout: float</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2Configs.DROPOUT`</span>

<span class="sd">    train_split: float</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.TRAIN_SPLIT`</span>

<span class="sd">    epochs: int</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.EPOCHS`</span>

<span class="sd">    lr: float</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.LR`</span>

<span class="sd">    adam_epsilon: float</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.ADAM_EPSILON`</span>

<span class="sd">    gradient_accumulation_steps: float</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.GRAD_ACUM_STEPS`</span>

<span class="sd">    fp16: bool</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.FP16`</span>

<span class="sd">    fp16_opt_level: str</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.FP16_OPT_LEVEL`</span>

<span class="sd">    log_steps: int</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.LOG_STEPS`</span>

<span class="sd">    ckpt_steps: int</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.CKPT_STEPS`</span>

<span class="sd">    checkpoint_path: Union[str, Path]</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.CHECKPOINT_PATH`</span>

<span class="sd">    log_dir: Union[str, Path]</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.LOG_DIR`</span>

<span class="sd">    model_name: str</span>
<span class="sd">        Default is :func:`~musicaiz.models.gpt_composer.GPT2TrainConfigs.MODEL_NAME`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">log_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
    <span class="n">log_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>
    <span class="n">checkpoint_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;Train&quot;</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Creating dataloaders...&quot;</span><span class="p">)</span>

    <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">val_dataloader</span> <span class="o">=</span> <span class="n">build_torch_loaders</span><span class="p">(</span>
        <span class="n">dataset_path</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span>
        <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">train_split</span><span class="o">=</span><span class="n">train_split</span><span class="p">,</span>
        <span class="n">is_splitted</span><span class="o">=</span><span class="n">is_splitted</span>
    <span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train samples </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> | Validation samples </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Train tokens </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">sequence_length</span><span class="si">}</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">            | Validation samples </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">sequence_length</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

    <span class="c1"># sample</span>
    <span class="n">sample_idx</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample len </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_idx</span><span class="p">)</span><span class="si">}</span><span class="s2"> data </span><span class="si">{</span><span class="n">sample_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;input shape: </span><span class="si">{</span><span class="n">sample_idx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">tokens</span> <span class="o">=</span> <span class="n">get_vocabulary</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">)</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vocabulary size is </span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># TODO: This needs to go into a separated method</span>
    <span class="c1"># Save hyperparams to json</span>
    <span class="k">if</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;gpt&quot;</span><span class="p">:</span>
        <span class="n">model_configs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">GPTConfigs</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;__&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">key</span>
        <span class="p">}</span>
    <span class="n">model_configs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;VOCAB_SIZE&quot;</span><span class="p">:</span> <span class="n">vocab_size</span><span class="p">})</span>
    <span class="n">train_configs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">TrainConfigs</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;__&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">key</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Path</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="n">configs_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;model_configs&quot;</span><span class="p">:</span> <span class="n">model_configs</span><span class="p">,</span>
        <span class="s2">&quot;train_configs&quot;</span><span class="p">:</span> <span class="n">train_configs</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">dir_configs</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">log_dir</span><span class="p">),</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;_configs.json&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dir_configs</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">outfile</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">configs_dict</span><span class="p">,</span> <span class="n">outfile</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saved configs.json in </span><span class="si">{</span><span class="n">dir_configs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Initialize model</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">initialize_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">configs_dict</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">PrettyTable</span><span class="p">([</span><span class="s2">&quot;Modules&quot;</span><span class="p">,</span> <span class="s2">&quot;Parameters&quot;</span><span class="p">])</span>
        <span class="n">total_params</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">parameter</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span> <span class="k">continue</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
            <span class="n">table</span><span class="o">.</span><span class="n">add_row</span><span class="p">([</span><span class="n">name</span><span class="p">,</span> <span class="n">params</span><span class="p">])</span>
            <span class="n">total_params</span><span class="o">+=</span><span class="n">params</span>
        <span class="k">return</span> <span class="n">table</span><span class="p">,</span> <span class="n">total_params</span>
    <span class="n">table</span><span class="p">,</span> <span class="n">total_params</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total trainable params: </span><span class="si">{</span><span class="n">total_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># write model params in txt</span>
    <span class="n">dir_params</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">log_dir</span><span class="p">),</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;_model.txt&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dir_params</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">results_file</span><span class="p">:</span>
        <span class="n">results_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">table</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2"> Total trainable params: </span><span class="si">{</span><span class="n">total_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">results_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">param_optimizer</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span>
    <span class="n">no_decay</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">,</span> <span class="s1">&#39;LayerNorm.weight&#39;</span><span class="p">]</span>
    <span class="n">optimizer_grouped_parameters</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param_optimizer</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)],</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param_optimizer</span> <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)],</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
    <span class="p">]</span>

    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span>
        <span class="n">optimizer_grouped_parameters</span><span class="p">,</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
        <span class="n">eps</span><span class="o">=</span><span class="n">adam_epsilon</span>
    <span class="p">)</span>

    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">OneCycleLR</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">max_lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">//</span> <span class="n">gradient_accumulation_steps</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
        <span class="n">pct_start</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
        <span class="n">anneal_strategy</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span>
    <span class="p">)</span>

    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">amp</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">opt_level</span><span class="o">=</span><span class="n">fp16_opt_level</span><span class="p">)</span>

    <span class="n">losses</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">global_steps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">local_steps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">step_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">train_perplexity</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">start_step</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">step_perplexity</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s1"> | Moved model to: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s1"> | train_batch_size: </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1"> | eval_batch_size: </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s1"> | Epochs: </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1"> | log_steps: </span><span class="si">{</span><span class="n">log_steps</span><span class="si">}</span><span class="s1"> | ckpt_steps: </span><span class="si">{</span><span class="n">ckpt_steps</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s1"> | gradient_accumulation_steps: </span><span class="si">{</span><span class="n">gradient_accumulation_steps</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># Reset gradients tensors</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>  <span class="c1"># tqdm(range(epochs), desc=&#39;Epochs&#39;, position=0):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s2"> | Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">pb</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span>
            <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
            <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
            <span class="n">bar_format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{l_bar}{bar:10}{r_bar}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">pb</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="n">start_step</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">batch</span>  <span class="c1"># _ is input_mask</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">lm_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">lm_logits</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

            <span class="c1"># if we don&#39;t use softmax at the end of last layer</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">shift_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

            <span class="n">step_perplexity</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="n">origin_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">gradient_accumulation_steps</span>  <span class="c1"># divide loss into gradient accumulation step</span>
            <span class="k">if</span> <span class="n">fp16</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">amp</span><span class="o">.</span><span class="n">scale_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span> <span class="k">as</span> <span class="n">scaled_loss</span><span class="p">:</span>
                    <span class="n">scaled_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">step_loss</span> <span class="o">=</span> <span class="n">origin_loss</span>
            <span class="n">losses</span><span class="p">[</span><span class="n">global_steps</span><span class="p">]</span> <span class="o">=</span> <span class="n">origin_loss</span>

            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">train_perplexity</span> <span class="o">+=</span> <span class="n">step_perplexity</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="n">local_steps</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">global_steps</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">global_steps</span> <span class="o">%</span> <span class="n">gradient_accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">fp16</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">amp</span><span class="o">.</span><span class="n">master_params</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="n">total_train_loss</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="n">local_steps</span>
            <span class="n">total_train_perplexity</span> <span class="o">=</span> <span class="n">train_perplexity</span> <span class="o">/</span> <span class="n">local_steps</span>

            <span class="n">step_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">local_steps</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="n">dir_train</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">log_dir</span><span class="p">),</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;_train_results.txt&quot;</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dir_train</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">results_file</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">results_file</span><span class="p">)</span>
            <span class="n">results_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

            <span class="c1"># Evaluate every epoch</span>
            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="n">eval_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">eval_steps</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span>
                <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_dataloader</span><span class="p">),</span>
                <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">val_dataloader</span><span class="p">),</span>
                <span class="n">bar_format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">{l_bar}{bar:10}{r_bar}</span><span class="s1">&#39;</span>
            <span class="p">):</span>

                <span class="n">inputs</span> <span class="o">=</span> <span class="n">batch</span>  <span class="c1"># _ is input_mask</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">lm_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">lm_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                
                <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">lm_logits</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

                <span class="c1"># if we don&#39;t use spftmax at the end of last layer</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">shift_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

                <span class="n">tmp_eval_loss</span> <span class="o">=</span> <span class="n">loss</span>
                <span class="n">tmp_perplexity</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tmp_eval_loss</span><span class="p">)</span>

                <span class="n">eval_loss</span> <span class="o">+=</span> <span class="n">tmp_eval_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">perplexity</span> <span class="o">+=</span> <span class="n">tmp_perplexity</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">eval_steps</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="n">total_eval_loss</span> <span class="o">=</span> <span class="n">eval_loss</span> <span class="o">/</span> <span class="n">eval_steps</span>
                <span class="n">total_perplexity</span> <span class="o">=</span> <span class="n">perplexity</span> <span class="o">/</span> <span class="n">eval_steps</span>

                <span class="n">dir_eval</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">log_dir</span><span class="p">),</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;_eval_results.txt&quot;</span><span class="p">)</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dir_eval</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">results_file</span><span class="p">:</span>
                    <span class="n">results_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s1"> | Step: </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s1"> | Eval Loss: </span><span class="si">{</span><span class="n">total_eval_loss</span><span class="si">}</span><span class="s1"> | Perplexity: </span><span class="si">{</span><span class="n">total_perplexity</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span>
                    <span class="p">)</span>
                    <span class="n">results_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

            <span class="c1"># We finished 1 global step</span>
            <span class="c1"># write csv with results</span>
            <span class="n">csv_eval</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">log_dir</span><span class="p">),</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;_results.csv&quot;</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">csv_eval</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">results_file</span><span class="p">:</span>
                <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">results_file</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">global_steps</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="s2">&quot;Step&quot;</span><span class="p">,</span> <span class="s2">&quot;Train PPL&quot;</span><span class="p">,</span> <span class="s2">&quot;Eval PPL&quot;</span><span class="p">,</span> <span class="s2">&quot;Train Loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Eval Loss&quot;</span><span class="p">])</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="n">global_steps</span><span class="p">,</span> <span class="n">total_train_loss</span><span class="p">,</span> <span class="n">total_perplexity</span><span class="p">,</span> <span class="n">total_train_perplexity</span><span class="p">,</span> <span class="n">total_eval_loss</span><span class="p">])</span>
                <span class="n">results_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

            <span class="n">pb</span><span class="o">.</span><span class="n">set_postfix_str</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s2"> | Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> | Global Step: </span><span class="si">{</span><span class="n">global_steps</span><span class="si">}</span><span class="s2"> | Train Loss: </span><span class="si">{</span><span class="n">origin_loss</span><span class="si">}</span><span class="s2"> | Train PPL: </span><span class="si">{</span><span class="n">step_perplexity</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span> \
            <span class="p">)</span>
            <span class="n">pb</span><span class="o">.</span><span class="n">set_postfix_str</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s2"> | Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> | Global Step: </span><span class="si">{</span><span class="n">global_steps</span><span class="si">}</span><span class="s2"> | Eval Loss: </span><span class="si">{</span><span class="n">total_eval_loss</span><span class="si">}</span><span class="s2"> | Perplexity: </span><span class="si">{</span><span class="n">total_perplexity</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">start_step</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">if</span> <span class="n">global_steps</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
                    <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                    <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">&#39;losses&#39;</span><span class="p">:</span> <span class="n">losses</span><span class="p">,</span>
                    <span class="s1">&#39;train_step&#39;</span><span class="p">:</span> <span class="n">global_steps</span><span class="p">,</span>
                    <span class="s1">&#39;amp&#39;</span><span class="p">:</span> <span class="n">amp</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
                    <span class="p">},</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s1">/ep</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">_step</span><span class="si">{</span><span class="n">global_steps</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">.pth&#39;</span>
                <span class="p">)</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s1"> | Saved checkpoint to: </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s1"> </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
                <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">&#39;losses&#39;</span><span class="p">:</span> <span class="n">losses</span><span class="p">,</span>
                <span class="s1">&#39;train_step&#39;</span><span class="p">:</span> <span class="n">global_steps</span><span class="p">,</span>
                <span class="s1">&#39;amp&#39;</span><span class="p">:</span> <span class="n">amp</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
                <span class="p">},</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s1">/ep</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">.pth&#39;</span>
            <span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s1"> | Saved checkpoint to: </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s1"> </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
        <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
        <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s1">&#39;losses&#39;</span><span class="p">:</span> <span class="n">losses</span><span class="p">,</span>
        <span class="s1">&#39;train_step&#39;</span><span class="p">:</span> <span class="n">global_steps</span><span class="p">,</span>
        <span class="s1">&#39;amp&#39;</span><span class="p">:</span> <span class="n">amp</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="p">},</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s1">/ep</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">.pth&#39;</span>
    <span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s1"> | Saved checkpoint to: </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s1"> </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">parse_args</span><span class="p">():</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--dataset_path&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--sequence_length&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">GPTConfigs</span><span class="o">.</span><span class="n">SEQ_LEN</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--batch_size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--train_split&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">TRAIN_SPLIT</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--is_splitted&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">IS_SPLITTED</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--epochs&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">LR</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--adam_epsilon&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">ADAM_EPSILON</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--gradient_accumulation_steps&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">GRAD_ACUM_STEPS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--fp16&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">FP16</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--fp16_opt_level&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">FP16_OPT_LEVEL</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--log_steps&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">LOG_STEPS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--ckpt_steps&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">CKPT_STEPS</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--checkpoint_path&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--log_dir&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">LOG_DIR</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--model_name&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">TrainConfigs</span><span class="o">.</span><span class="n">MODEL_NAME</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>
    <span class="n">train</span><span class="p">(</span>
        <span class="n">dataset_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">,</span>
        <span class="n">train_split</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_split</span><span class="p">,</span>
        <span class="n">is_splitted</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">is_splitted</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
        <span class="n">adam_epsilon</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adam_epsilon</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
        <span class="n">fp16</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">fp16</span><span class="p">,</span>
        <span class="n">fp16_opt_level</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">fp16_opt_level</span><span class="p">,</span>
        <span class="n">log_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">log_steps</span><span class="p">,</span>
        <span class="n">ckpt_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ckpt_steps</span><span class="p">,</span>
        <span class="n">checkpoint_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">,</span>
        <span class="n">log_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span>
        <span class="n">model_name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
    <span class="p">)</span>
    
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Carlos Hernandez-Olivan.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>